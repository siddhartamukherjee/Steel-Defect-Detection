{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4076c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (Normalize, Compose)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch.utils.data as data\n",
    "from Resnet_UNet import ResNetUNet\n",
    "from Data_Retriever_Inference import TestDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbd57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b809fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((224, 224), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a1e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = './sample_submission.csv'\n",
    "test_data_folder = \"./test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55189f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold 0.5\n"
     ]
    }
   ],
   "source": [
    "# initialize test dataloader\n",
    "best_threshold = 0.5\n",
    "num_workers = 2\n",
    "batch_size = 4\n",
    "print('best_threshold', best_threshold)\n",
    "min_size = 3500\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fa5283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize mode and load trained weights\n",
    "ckpt_path = \"model.pth\"\n",
    "device = torch.device(\"cuda:0,1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetUNet(n_class=4)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "#print(state[\"state_dict\"])\n",
    "model.load_state_dict(state[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f942cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1377/1377 [33:14<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# start prediction\n",
    "predictions = []\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    fnames, images = batch\n",
    "    batch_preds = torch.sigmoid(model(images.to(device)))\n",
    "    batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16ba2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
